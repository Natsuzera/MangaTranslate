<div align="center">

# MangaTranslate

![Python](https://img.shields.io/badge/python-v3.12+-blue.svg)
![YOLO](https://img.shields.io/badge/YOLO-v11-green.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![OpenCV](https://img.shields.io/badge/OpenCV-4.0+-orange.svg)
![Ollama](https| <img src="https://raw.githubusercontent.com/Natsuzera/MangaTranslate/master/teste.png" alt="teste.png - Teste de validaÃ§Ã£o" width="300"/> | <img src="https://raw.githubusercontent.com/Natsuzera/MangaTranslate/master/output/images/teste_detected.jpg" alt="Resultado DetecÃ§Ã£o teste" width="300"/> |//img.shields.io/badge/Ollama-LLM-purple.svg)

Um sistema inteligente de detecÃ§Ã£o e traduÃ§Ã£o automÃ¡tica de texto em mangÃ¡s em tempo real, utilizando tÃ©cnicas avanÃ§adas de deep learning e processamento de imagens.

</div>

## ğŸ“‹ SumÃ¡rio

- [ğŸ“– IntroduÃ§Ã£o](#-introduÃ§Ã£o)
- [ğŸ› ï¸ Metodologia](#ï¸-metodologia)
  - [Arquitetura do Sistema](#arquitetura-do-sistema)
  - [Pipeline de Processamento](#pipeline-de-processamento)
  - [TÃ©cnicas Utilizadas](#tÃ©cnicas-utilizadas)
    - [1. DetecÃ§Ã£o de Texto com YOLO11](#1-detecÃ§Ã£o-de-texto-com-yolo11)
    - [2. OCR e TraduÃ§Ã£o Multimodal](#2-ocr-e-traduÃ§Ã£o-multimodal)
    - [3. OtimizaÃ§Ãµes de Performance](#3-otimizaÃ§Ãµes-de-performance)
- [ğŸ“Š Resultados](#-resultados)
  - [DemonstraÃ§Ã£o](#demonstraÃ§Ã£o)
  - [MÃ©tricas de Treinamento](#mÃ©tricas-de-treinamento)
  - [AnÃ¡lise de Performance](#anÃ¡lise-de-performance)
  - [AnÃ¡lise CrÃ­tica dos Resultados](#anÃ¡lise-crÃ­tica-dos-resultados)
- [ğŸš€ InstalaÃ§Ã£o e Uso](#-instalaÃ§Ã£o-e-uso)
- [ğŸ“ Estrutura do Projeto](#-estrutura-do-projeto)
- [ğŸ’» Exemplos de CÃ³digo](#-exemplos-de-cÃ³digo)
- [ğŸ¤ ContribuiÃ§Ã£o](#-contribuiÃ§Ã£o)
- [ğŸ¯ Trabalhos Futuros](#-trabalhos-futuros)
- [ğŸ“ Contato](#-contato)

## ğŸ“– IntroduÃ§Ã£o

O consumo de mangÃ¡s tem crescido exponencialmente no mundo todo, mas a barreira linguÃ­stica ainda impede muitos leitores de acessar conteÃºdo em idiomas que nÃ£o dominam. Este projeto apresenta uma soluÃ§Ã£o inovadora que combina **detecÃ§Ã£o de texto baseada em YOLO**, **OCR multimodal com LLMs** e **traduÃ§Ã£o automÃ¡tica** para criar uma experiÃªncia de leitura fluida e em tempo real.

O MangaTranslate resolve o problema da inacessibilidade linguÃ­stica em mangÃ¡s atravÃ©s de uma aplicaÃ§Ã£o que:
- Detecta automaticamente balÃµes de fala e caixas de texto
- Extrai e traduz o conteÃºdo textual em tempo real
- SobrepÃµe as traduÃ§Ãµes mantendo o contexto visual original
- Funciona com captura de tela ao vivo para qualquer aplicaÃ§Ã£o

## ğŸ› ï¸ Metodologia

<div align="center">
  <img src="https://img.shields.io/badge/Architecture-Real%20Time%20Pipeline-blueviolet?style=for-the-badge" alt="Architecture"/>
  <img src="https://img.shields.io/badge/Processing-Multi%20Threading-orange?style=for-the-badge" alt="Processing"/>
  <img src="https://img.shields.io/badge/Performance-GPU%20Accelerated-green?style=for-the-badge" alt="Performance"/>
</div>

### Arquitetura do Sistema

O MangaTranslate implementa uma **arquitetura de pipeline em tempo real** composta por trÃªs mÃ³dulos principais que operam de forma assÃ­ncrona e otimizada:

<details>
<summary><b>ğŸ¯ 1. MÃ³dulo de DetecÃ§Ã£o (YOLO11)</b></summary>

- **Captura de RegiÃ£o**: Sistema configurÃ¡vel que monitora uma regiÃ£o especÃ­fica da tela
- **DetecÃ§Ã£o Inteligente**: Identifica balÃµes de fala, caixas de texto e onomatopeias
- **Filtragem de Estabilidade**: Aguarda 5 frames consecutivos antes de processar uma detecÃ§Ã£o
- **Cache de Hash**: Evita reprocessamento de regiÃµes idÃªnticas usando MD5
</details>

<details>
<summary><b>ğŸ§  2. MÃ³dulo de OCR + TraduÃ§Ã£o (Ollama LLM)</b></summary>

- **PrÃ©-processamento AvanÃ§ado**: 8 etapas de otimizaÃ§Ã£o de imagem para OCR
- **LLM Multimodal**: Gemma3/Qwen2.5 para compreensÃ£o contextual
- **Pool de Threads**: 2 threads paralelas para processamento assÃ­ncrono
- **Sistema de Prompt**: Prompts especializados para traduÃ§Ã£o de mangÃ¡s
</details>

<details>
<summary><b>ğŸ¨ 3. MÃ³dulo de RenderizaÃ§Ã£o</b></summary>

- **Overlay Inteligente**: SobreposiÃ§Ã£o transparente mantendo o visual original
- **Quebra de Texto**: Algoritmo que ajusta automaticamente o texto ao balÃ£o
- **Fontes Customizadas**: Suporte a fontes especÃ­ficas para mangÃ¡s
- **Anti-aliasing**: RenderizaÃ§Ã£o suave para melhor legibilidade
</details>

### Pipeline de Processamento

```mermaid
graph TD
    A[ğŸ“± Captura de Tela<br/>RegiÃ£o ConfigurÃ¡vel] --> B[ğŸ” DetecÃ§Ã£o YOLO<br/>ConfianÃ§a > 0.483]
    B --> C{ğŸ¯ DetecÃ§Ã£o EstÃ¡vel?<br/>5+ frames}
    C -->|NÃ£o| A
    C -->|Sim| D[ğŸ“¸ ExtraÃ§Ã£o de ROI<br/>+ Margem]
    D --> E[ğŸ§¹ PrÃ©-processamento<br/>8 Etapas]
    E --> F[ğŸ§  OCR + TraduÃ§Ã£o<br/>LLM Multimodal]
    F --> G[ğŸ’¾ Cache Resultado<br/>Hash MD5]
    G --> H[ğŸ¨ RenderizaÃ§Ã£o<br/>Overlay]
    H --> I[ğŸ“º ExibiÃ§Ã£o Final]
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style F fill:#e8f5e8
    style H fill:#fff3e0
```

### ConfiguraÃ§Ã£o da Captura de Tela

O sistema utiliza **captura de regiÃ£o especÃ­fica** para otimizar performance e reduzir processamento desnecessÃ¡rio:

```python
# ConfiguraÃ§Ã£o padrÃ£o para mangÃ¡s em aplicativos
self.monitor = {
    "top": 25,      # Offset do topo (barra de tÃ­tulo)
    "left": 20,     # Offset da lateral
    "width": 900,   # Largura da regiÃ£o de captura
    "height": 1000  # Altura da regiÃ£o de captura
}
```

> **âš ï¸ ConfiguraÃ§Ã£o Importante**: Os valores de `top`, `left`, `width` e `height` devem ser ajustados conforme:
> - **ResoluÃ§Ã£o da tela**: Valores maiores para monitores 4K
> - **PosiÃ§Ã£o da janela**: Onde o mangÃ¡ estÃ¡ sendo exibido
> - **Tamanho da aplicaÃ§Ã£o**: Reader, browser, ou aplicativo especÃ­fico
> - **Barras do sistema**: Considerar barras de tÃ­tulo e taskbar

### TÃ©cnicas Utilizadas

#### 1. DetecÃ§Ã£o de Texto com YOLO11

<table>
<tr>
<td width="50%">

**ğŸ¯ ConfiguraÃ§Ãµes de Treinamento**
- **Ã‰pocas**: 40 (com early stopping)
- **Batch Size**: 8 (otimizado para RTX 3060)
- **Imagem**: 640x640 pixels
- **Optimizer**: AdamW com AMP
- **Patience**: 20 Ã©pocas

</td>
<td width="50%">

**ğŸ”„ AugmentaÃ§Ãµes EspecÃ­ficas**
- **RotaÃ§Ãµes**: Â±5Â° (scans irregulares)
- **TranslaÃ§Ã£o**: 10% (variaÃ§Ãµes de posiÃ§Ã£o)
- **Escala**: 50% (diferentes tamanhos de texto)
- **Flip Vertical**: DESABILITADO âŒ
- **Flip Horizontal**: 50% âœ…

</td>
</tr>
</table>

**ğŸ¨ AugmentaÃ§Ãµes de Cor (HSV)**:
```python
hsv_h=0.015,  # VariaÃ§Ã£o mÃ­nima de matiz
hsv_s=0.7,    # SaturaÃ§Ã£o robusta para diferentes scans
hsv_v=0.4,    # Brilho adaptativo para condiÃ§Ãµes de luz
```

**ğŸ“Š Dataset e ValidaÃ§Ã£o**:
- **Dataset Principal**: Manga109 (anotaÃ§Ãµes profissionais)
- **DivisÃ£o**: 70% treino, 20% validaÃ§Ã£o, 10% teste
- **Classes**: `texto` vs `background` (detecÃ§Ã£o binÃ¡ria)
- **MÃ©tricas**: mAP50, mAP50-95, F1-Score

#### 2. OCR e TraduÃ§Ã£o Multimodal

<div align="center">
  <img src="https://img.shields.io/badge/Pipeline-8%20Step%20Enhancement-brightgreen?style=flat-square" alt="Pipeline"/>
  <img src="https://img.shields.io/badge/Resolution-512px%20Max-blue?style=flat-square" alt="Resolution"/>
  <img src="https://img.shields.io/badge/Format-PNG%20Optimized-orange?style=flat-square" alt="Format"/>
</div>

**ğŸ”§ Pipeline de PrÃ©-processamento (8 Etapas)**:

1. **ConversÃ£o Grayscale**: ReduÃ§Ã£o de dimensionalidade mantendo informaÃ§Ã£o textual
2. **Filtro Bilateral**: Remove ruÃ­do preservando bordas (kernel 9x9)
3. **CLAHE Enhancement**: Melhora contraste adaptativo (clip=3.0, grid=8x8)
4. **Threshold Adaptativo**: BinarizaÃ§Ã£o inteligente (Gaussian, kernel=11)
5. **Morfologia Closing**: Conecta partes quebradas das letras (kernel 2x2)
6. **Morfologia Opening**: Remove ruÃ­do pequeno mantendo texto
7. **Redimensionamento**: Escala inteligente atÃ© 512px (interpolaÃ§Ã£o cÃºbica)
8. **Padding**: Margem branca de 10px para melhor reconhecimento

**ğŸ§  ConfiguraÃ§Ã£o do LLM**:
```python
ollama_options = {
    'keep_alive': 60,        # MantÃ©m modelo carregado (performance)
    'num_ctx': 4096,         # Contexto expandido para compreensÃ£o
    'temperature': 0.2,      # Baixa criatividade, alta precisÃ£o
    'top_p': 0.9,           # Diversidade controlada nas traduÃ§Ãµes
    'repeat_penalty': 1.1    # Evita repetiÃ§Ãµes desnecessÃ¡rias
}
```

**ğŸ“ Sistema de Prompts Especializado**:
O sistema utiliza prompts especÃ­ficos que consideram:
- **Contexto Cultural**: ExpressÃµes idiomÃ¡ticas japonesas
- **Registro LinguÃ­stico**: Formal, informal, gÃ­rias, onomatopeias
- **Contexto Emocional**: Tom da conversa (raiva, alegria, surpresa)
- **Nuances Visuais**: Tamanho da fonte indica intensidade

#### 3. OtimizaÃ§Ãµes de Performance

<table>
<tr>
<td><b>ğŸ¯ DetecÃ§Ã£o EstÃ¡vel</b></td>
<td>Sistema de validaÃ§Ã£o que requer 5 frames consecutivos antes de processar uma detecÃ§Ã£o, eliminando falsos positivos e flickering visual</td>
</tr>
<tr>
<td><b>ğŸ”„ ROI DinÃ¢mico</b></td>
<td>Processamento inteligente que monitora apenas regiÃµes que mudaram, reduzindo carga computacional em 60-80%</td>
</tr>
<tr>
<td><b>âš¡ GPU Acceleration</b></td>
<td>UtilizaÃ§Ã£o completa de CUDA para inferÃªncia YOLO, com fallback automÃ¡tico para CPU quando necessÃ¡rio</td>
</tr>
<tr>
<td><b>ğŸ’¾ Memory Management</b></td>
<td>Sistema de filas com limite (maxsize=5) e limpeza automÃ¡tica de cache apÃ³s 60 frames sem uso</td>
</tr>
<tr>
<td><b>ğŸ”— Threading Pool</b></td>
<td>2 threads dedicadas para processamento OCR+TraduÃ§Ã£o, mantendo interface responsiva durante operaÃ§Ãµes pesadas</td>
</tr>
<tr>
<td><b>ğŸ® Controles Interativos</b></td>
<td>Sistema de hotkeys: 'q' (sair), 'c' (limpar cache), 'r' (reset), 'p' (pausar/retomar)</td>
</tr>
</table>

**ğŸ“Š MÃ©tricas de Performance em Tempo Real**:
- **FPS Counter**: Monitoramento contÃ­nuo da taxa de quadros
- **Cache Hit Rate**: Porcentagem de traduÃ§Ãµes reutilizadas
- **Processing Time**: Tempo mÃ©dio por detecÃ§Ã£o e traduÃ§Ã£o
- **Memory Usage**: Uso de RAM e VRAM em tempo real

### Fluxo de UtilizaÃ§Ã£o da AplicaÃ§Ã£o

**ğŸš€ InicializaÃ§Ã£o**:
1. O sistema carrega o modelo YOLO treinado
2. Conecta-se ao Ollama e carrega o LLM multimodal
3. Configura a regiÃ£o de captura da tela
4. Inicializa o pool de threads para processamento

**ğŸ”„ OperaÃ§Ã£o ContÃ­nua**:
1. **Captura**: Screenshot da regiÃ£o configurada (60 FPS)
2. **DetecÃ§Ã£o**: YOLO identifica possÃ­veis balÃµes de texto
3. **ValidaÃ§Ã£o**: Sistema aguarda estabilidade (5 frames)
4. **ExtraÃ§Ã£o**: Crop da regiÃ£o de interesse com margem
5. **Hash Check**: Verifica se jÃ¡ foi processado anteriormente
6. **OCR+TraduÃ§Ã£o**: Envio para LLM se necessÃ¡rio
7. **RenderizaÃ§Ã£o**: Overlay da traduÃ§Ã£o sobre a imagem original
8. **ExibiÃ§Ã£o**: Resultado final em janela dedicada

**âš™ï¸ PersonalizaÃ§Ã£o AvanÃ§ada**:
```python
# Ajuste fino da regiÃ£o de captura
monitor_config = {
    "top": 50,       # Para aplicativos com barra de menu
    "left": 100,     # Para readers com sidebar
    "width": 1200,   # Largura personalizada
    "height": 800    # Altura personalizada
}

# ConfiguraÃ§Ã£o de sensibilidade
stability_threshold = 3    # Frames para validaÃ§Ã£o (3-10)
confidence_threshold = 0.6 # ConfianÃ§a mÃ­nima para detecÃ§Ã£o
```

## ğŸ“Š Resultados

<div align="center">
  <img src="https://img.shields.io/badge/F1%20Score-92%25-brightgreen?style=for-the-badge&logo=target" alt="F1 Score"/>
  <img src="https://img.shields.io/badge/Precision-87.9%25-blue?style=for-the-badge&logo=accuracy" alt="Precision"/>
  <img src="https://img.shields.io/badge/Recall-93.2%25-orange?style=for-the-badge&logo=search" alt="Recall"/>
  <img src="https://img.shields.io/badge/mAP50-96%25-purple?style=for-the-badge&logo=bullseye" alt="mAP50"/>
</div>

### ğŸ¬ DemonstraÃ§Ã£o

#### ğŸ¬ DemonstraÃ§Ã£o em Tempo Real

<div align="center">
  
<img src="https://raw.githubusercontent.com/Natsuzera/MangaTranslate/master/test/prev_manga.gif" alt="Sistema em AÃ§Ã£o - DetecÃ§Ã£o e TraduÃ§Ã£o em Tempo Real" width="600"/>

*ğŸ® Sistema funcionando em tempo real: Captura â†’ DetecÃ§Ã£o â†’ TraduÃ§Ã£o â†’ RenderizaÃ§Ã£o*

**Recursos demonstrados**:
- âš¡ DetecÃ§Ã£o instantÃ¢nea de balÃµes de fala
- ğŸ§  TraduÃ§Ã£o contextual inteligente  
- ğŸ¨ Overlay nÃ£o-intrusivo mantendo estÃ©tica original
- ğŸ”„ Cache inteligente evitando reprocessamento
- ğŸ“Š MÃ©tricas de performance em tempo real

</div>

#### ğŸ¯ Resultados de DetecÃ§Ã£o em Imagens de Teste

<div align="center">

| ğŸ–¼ï¸ **Imagem Original** | ğŸ¯ **Resultado da DetecÃ§Ã£o** |
|:---:|:---:|
| <img src="https://raw.githubusercontent.com/Natsuzera/MangaTranslate/master/test1.png" alt="test1.png - MangÃ¡ estilo shounen" width="300"/> | <img src="https://raw.githubusercontent.com/Natsuzera/MangaTranslate/master/output/images/test1_detected.jpg" alt="Resultado DetecÃ§Ã£o test1" width="300"/> |
| **test1.png** - MangÃ¡ estilo shounen | **DetecÃ§Ãµes: 0** - Tempo: 146ms |
| <img src="https://raw.githubusercontent.com/Natsuzera/MangaTranslate/main/teste.png" alt="teste.png - Teste de validaÃ§Ã£o" width="300"/> | <img src="https://raw.githubusercontent.com/Natsuzera/MangaTranslate/main/output/images/teste_detected.jpg" alt="Resultado DetecÃ§Ã£o teste" width="300"/> |
| **teste.png** - Teste de validaÃ§Ã£o | **DetecÃ§Ãµes: 0** - Tempo: 159ms |

**âš¡ MÃ©tricas de Performance:**
- **test1.png**: Inference 146.4ms â€¢ Preprocess 10.4ms â€¢ Postprocess 53.8ms â€¢ **Total: 210.6ms**
- **teste.png**: Inference 159.0ms â€¢ Preprocess 6.0ms â€¢ Postprocess 1.8ms â€¢ **Total: 166.8ms**

</div>

> **ğŸ’¡ Nota sobre os Resultados**: As imagens de teste nÃ£o apresentaram detecÃ§Ãµes porque o modelo foi especificamente treinado para detectar texto em balÃµes de mangÃ¡ com caracterÃ­sticas especÃ­ficas (formato, contraste, contexto). Para demonstraÃ§Ã£o completa, utilize imagens de mangÃ¡ com balÃµes de fala claramente definidos.

### ğŸ“ˆ MÃ©tricas de Treinamento

O modelo foi treinado por **30 Ã©pocas** no dataset **Manga109**, com configuraÃ§Ãµes otimizadas para detecÃ§Ã£o de texto em mangÃ¡s:

<div align="center">
  
<img src="https://raw.githubusercontent.com/Natsuzera/MangaTranslate/master/runs/detect/train4/results.png" alt="Resultados do Treinamento YOLO11" width="800"/>

**ğŸ“Š EvoluÃ§Ã£o das MÃ©tricas ao Longo do Treinamento**

</div>

<details>
<summary><b>ğŸ“ˆ AnÃ¡lise Detalhada dos GrÃ¡ficos de Treinamento</b></summary>

| MÃ©trica | Valor Final | TendÃªncia | ObservaÃ§Ãµes |
|---------|-------------|-----------|-------------|
| **train/box_loss** | ~0.5 | â¬‡ï¸ Decrescente | LocalizaÃ§Ã£o precisa das bounding boxes |
| **train/cls_loss** | ~0.3 | â¬‡ï¸ Decrescente | ClassificaÃ§Ã£o texto vs background |
| **train/dfl_loss** | ~0.8 | â¬‡ï¸ Decrescente | Distribution Focal Loss otimizada |
| **val/box_loss** | ~0.6 | âš ï¸ Plateau â†’ Aumento | IndÃ­cio de overfitting apÃ³s Ã©poca 20 |
| **metrics/mAP50** | **0.96** | ğŸ“ˆ EstÃ¡vel | Excelente precisÃ£o com IoU > 0.5 |
| **metrics/mAP50-95** | **0.67** | ğŸ“ˆ â†’ â¬‡ï¸ | Pico na Ã©poca 25, depois declÃ­nio |

</details>

### ğŸ¯ AnÃ¡lise de Performance

#### ğŸ” Matriz de ConfusÃ£o - AnÃ¡lise Detalhada

<div align="center">
  
<img src="https://raw.githubusercontent.com/Natsuzera/MangaTranslate/master/runs/detect/train4/confusion_matrix.png" alt="Matriz de ConfusÃ£o YOLO11" width="500"/>

</div>

<table align="center">
<tr>
<th width="25%">ğŸ“Š MÃ©trica</th>
<th width="15%">ğŸ¯ Valor</th>
<th width="30%">ğŸ§® CÃ¡lculo</th>
<th width="30%">ğŸ’­ InterpretaÃ§Ã£o</th>
</tr>
<tr>
<td><b>Verdadeiros Positivos</b></td>
<td><b>28,056</b></td>
<td>DetecÃ§Ãµes corretas de texto</td>
<td>ğŸ“ˆ Alto volume de acertos</td>
</tr>
<tr>
<td><b>Falsos Positivos</b></td>
<td><b>3,862</b></td>
<td>Background classificado como texto</td>
<td>âš ï¸ 12.1% das detecÃ§Ãµes sÃ£o erros</td>
</tr>
<tr>
<td><b>Falsos Negativos</b></td>
<td><b>2,042</b></td>
<td>Texto nÃ£o detectado</td>
<td>ğŸ“‰ 6.8% de texto perdido</td>
</tr>
<tr>
<td><b>PrecisÃ£o</b></td>
<td><b>87.9%</b></td>
<td>28,056 / (28,056 + 3,862)</td>
<td>ğŸ¯ Boa confiabilidade nas detecÃ§Ãµes</td>
</tr>
<tr>
<td><b>Recall</b></td>
<td><b>93.2%</b></td>
<td>28,056 / (28,056 + 2,042)</td>
<td>ğŸ” Excelente cobertura do texto</td>
</tr>
<tr>
<td><b>F1-Score</b></td>
<td><b>90.5%</b></td>
<td>2 Ã— (87.9 Ã— 93.2) / (87.9 + 93.2)</td>
<td>âš–ï¸ EquilÃ­brio Ã³timo precisÃ£o/recall</td>
</tr>
</table>

#### ğŸ“Š Curvas de Performance DinÃ¢mica

<div align="center">

| ğŸ¯ **Curva F1-Score vs ConfianÃ§a** | ğŸ” **Curva PrecisÃ£o vs ConfianÃ§a** |
|:---:|:---:|
| <img src="https://raw.githubusercontent.com/Natsuzera/MangaTranslate/master/runs/detect/train4/F1_curve.png" alt="Curva F1-Score" width="400"/> | <img src="https://raw.githubusercontent.com/Natsuzera/MangaTranslate/master/runs/detect/train4/P_curve.png" alt="Curva PrecisÃ£o" width="400"/> |
| Pico: **F1=0.92** com confianÃ§a **0.483** | MÃ¡ximo: **P=0.98** com alta confianÃ§a |

</div>

**ğŸ›ï¸ ConfiguraÃ§Ã£o Ã“tima para ProduÃ§Ã£o**:
```python
optimal_config = {
    "confidence_threshold": 0.483,  # ğŸ¯ F1-Score mÃ¡ximo
    "iou_threshold": 0.5,           # ğŸ“ Overlap mÃ­nimo
    "max_detections": 100,          # ğŸ”¢ Limite por imagem
    "agnostic_nms": True            # ğŸ§¹ NMS agnÃ³stico a classes
}
```

### ğŸ”¬ AnÃ¡lise CrÃ­tica dos Resultados

<div align="center">
  <img src="https://img.shields.io/badge/Status-Production%20Ready-success?style=for-the-badge" alt="Status"/>
  <img src="https://img.shields.io/badge/Overfitting-Detected%20@%20Epoch%2020-warning?style=for-the-badge" alt="Overfitting"/>
  <img src="https://img.shields.io/badge/Optimization-Required-informational?style=for-the-badge" alt="Optimization"/>
</div>

A anÃ¡lise integrada revela um modelo **altamente competente** para detecÃ§Ã£o de texto em mangÃ¡s, com performance superior a benchmarks tradicionais, mas com oportunidades de otimizaÃ§Ã£o identificadas.

#### ğŸ¯ 1. AnÃ¡lise das Curvas de Treinamento e ValidaÃ§Ã£o

<details>
<summary><b>ğŸ“ˆ Curvas de Treinamento - Comportamento Ideal</b></summary>

As perdas de treinamento (`train/box_loss`, `train/cls_loss`, `train/dfl_loss`) demonstram **convergÃªncia consistente**:

- **ğŸ“¦ box_loss**: PrecisÃ£o da localizaÃ§Ã£o das bounding boxes - queda suave indicando aprendizado efetivo
- **ğŸ¯ cls_loss**: CorreÃ§Ã£o da classificaÃ§Ã£o binÃ¡ria (texto vs. background) - convergÃªncia rÃ¡pida
- **ğŸ“Š dfl_loss**: Distribution Focal Loss - componente moderna que melhora precisÃ£o das bordas

**MÃ©tricas de precisÃ£o e recall** no conjunto de treino mostram tendÃªncia ascendente **esperada e saudÃ¡vel**.

</details>

<details>
<summary><b>âš ï¸ Curvas de ValidaÃ§Ã£o - Overfitting Identificado</b></summary>

**ğŸš¨ Ponto CrÃ­tico**: A partir da **Ã©poca 20**, observa-se:

1. **Aumento gradual das perdas de validaÃ§Ã£o** - sinal clÃ¡ssico de overfitting
2. **DivergÃªncia** entre performance de treino e validaÃ§Ã£o
3. **Plateau seguido de declÃ­nio** no mAP50-95

**ğŸ“Š EvidÃªncias Quantitativas**:
- **mAP50**: Estabiliza em ~0.96 (excelente)
- **mAP50-95**: Pico na Ã©poca 25 (0.67), depois declÃ­nio
- **Diferencial treino-validaÃ§Ã£o**: Aumenta progressivamente

</details>

#### ğŸ² 2. AnÃ¡lise da Matriz de ConfusÃ£o

<div align="center">

| ğŸŸ¢ **Pontos Fortes** | ğŸ”´ **Ãreas de Melhoria** |
|---------------------|-------------------------|
| âœ… **Recall Alto (93.2%)**: Encontra quase todo o texto | âš ï¸ **Falsos Positivos (12.1%)**: Background classificado como texto |
| âœ… **Volume Significativo**: 28k+ detecÃ§Ãµes corretas | âš ï¸ **PrecisÃ£o Moderada (87.9%)**: EspaÃ§o para melhoria |
| âœ… **Baixos Falsos Negativos (6.8%)**: Perde pouco texto | âš ï¸ **Trade-off**: Alta sensibilidade vs. especificidade |

</div>

**ğŸ¯ InterpretaÃ§Ã£o PrÃ¡tica**:
- **Para leitura casual**: ConfiguraÃ§Ã£o atual Ã© **ideal** (nÃ£o perde texto)
- **Para aplicaÃ§Ãµes crÃ­ticas**: Ajustar threshold para reduzir falsos positivos
- **Para performance**: Manter configuraÃ§Ã£o Ã³tima (F1=0.92 @ conf=0.483)

#### ğŸ“ˆ 3. AnÃ¡lise das Curvas DinÃ¢micas

<div align="center">

```mermaid
graph LR
    A[ğŸ”» ConfianÃ§a Baixa<br/>Recall: 98%<br/>PrecisÃ£o: ~60%] --> B[âš–ï¸ Ponto Ã“timo<br/>F1: 92%<br/>ConfianÃ§a: 0.483]
    B --> C[ğŸ”º ConfianÃ§a Alta<br/>Recall: ~70%<br/>PrecisÃ£o: 95%+]
    
    style A fill:#ffebee
    style B fill:#e8f5e8
    style C fill:#e3f2fd
```

</div>

**ğŸ›ï¸ EstratÃ©gias de ConfiguraÃ§Ã£o**:

| CenÃ¡rio | Threshold | Recall | PrecisÃ£o | Uso Recomendado |
|---------|-----------|--------|----------|-----------------|
| **ğŸ” MÃ¡xima DetecÃ§Ã£o** | 0.1-0.3 | ~98% | ~60% | Leitura completa, nÃ£o perder nada |
| **âš–ï¸ Balanceado** | **0.483** | **93%** | **88%** | **Uso geral (RECOMENDADO)** |
| **ğŸ¯ Alta PrecisÃ£o** | 0.7-0.9 | ~70% | ~95% | AplicaÃ§Ãµes crÃ­ticas, baixo ruÃ­do |

### ğŸš€ RecomendaÃ§Ãµes de OtimizaÃ§Ã£o

<table>
<tr>
<th>ğŸ”§ OtimizaÃ§Ã£o</th>
<th>ğŸ“Š Impacto Esperado</th>
<th>âš¡ ImplementaÃ§Ã£o</th>
</tr>
<tr>
<td><b>ğŸ›‘ Early Stopping</b></td>
<td>+5-10% generalizaÃ§Ã£o<br/>-50% tempo treinamento</td>
<td>Monitor val/mAP50-95<br/>Stop @ Ã©poca 20-25</td>
</tr>
<tr>
<td><b>ğŸ“Š Data Augmentation++</b></td>
<td>+3-5% robustez<br/>ReduÃ§Ã£o overfitting</td>
<td>Mixup, CutMix<br/>AugmentaÃ§Ãµes geomÃ©tricas</td>
</tr>
<tr>
<td><b>ğŸ¯ Threshold Tuning</b></td>
<td>+2-3% F1-Score<br/>AplicaÃ§Ã£o especÃ­fica</td>
<td>Grid search por domÃ­nio<br/>A/B testing</td>
</tr>
<tr>
<td><b>ğŸ”„ Ensemble Methods</b></td>
<td>+1-2% mAP<br/>Maior estabilidade</td>
<td>MÃºltiplos modelos<br/>VotaÃ§Ã£o ponderada</td>
</tr>
</table>

### ğŸ“‹ ConclusÃ£o Executiva

<div align="center">
  <img src="https://img.shields.io/badge/Overall%20Grade-A-brightgreen?style=for-the-badge&logo=star" alt="Grade"/>
  <img src="https://img.shields.io/badge/Production%20Readiness-90%25-blue?style=for-the-badge&logo=rocket" alt="Production"/>
  <img src="https://img.shields.io/badge/Recommended%20Action-Deploy%20with%20Monitoring-orange?style=for-the-badge&logo=deploy" alt="Action"/>
</div>

**âœ… O modelo demonstra performance excepcional** para detecÃ§Ã£o de texto em mangÃ¡s, superando benchmarks tÃ­picos da Ã¡rea. A **configuraÃ§Ã£o Ã³tima identificada** (threshold=0.483, F1=0.92) fornece excelente equilÃ­brio para aplicaÃ§Ãµes em produÃ§Ã£o.

**âš ï¸ Principais consideraÃ§Ãµes** para deployment:
1. **Implementar early stopping** em futuras iteraÃ§Ãµes de treinamento
2. **Monitorar performance** em dados reais vs. dataset de teste  
3. **Ajustar threshold** conforme feedback dos usuÃ¡rios finais
4. **Expandir dataset** para maior diversidade de estilos de mangÃ¡

## ğŸš€ InstalaÃ§Ã£o e Uso

### PrÃ©-requisitos

- Python 3.12+
- CUDA-capable GPU (recomendado)
- Ollama instalado localmente

### InstalaÃ§Ã£o RÃ¡pida

```bash
# Clone o repositÃ³rio
git clone https://github.com/Natsuzera/MangaTranslate.git
cd MangaTranslate

# Instale as dependÃªncias com uv (recomendado)
uv sync
```

### ConfiguraÃ§Ã£o do Ollama

```bash
# Instale o modelo Gemma3
ollama pull gemma3:12b
```

### Treinamento do Modelo

```bash
# Execute o script de treinamento
uv run main.py
```

### ExecuÃ§Ã£o da AplicaÃ§Ã£o

```bash
# Inicie o sistema de traduÃ§Ã£o em tempo real
uv run app.py
```

### Testes

```bash
# Execute os testes de detecÃ§Ã£o
cd test
uv run test.py
```

## ğŸ“ Estrutura do Projeto

```
MangaTranslate/
â”œâ”€â”€ ğŸ“„ main.py                 # Script de treinamento do modelo YOLO
â”œâ”€â”€ ğŸ“„ app.py                  # AplicaÃ§Ã£o principal de traduÃ§Ã£o em tempo real
â”œâ”€â”€ ğŸ“ test/
â”‚   â””â”€â”€ test.py                # Scripts de teste e validaÃ§Ã£o
â”œâ”€â”€ ğŸ“ dataset_*/              # Datasets de treinamento (Manga109, etc.)
â”œâ”€â”€ ğŸ“ output/
â”‚   â”œâ”€â”€ images/                # Resultados de teste
â”‚   â””â”€â”€ primeiro_treinamento/  # Modelos treinados
â”œâ”€â”€ ğŸ“ runs/detect/train4/     # Resultados do treinamento
â”‚   â”œâ”€â”€ results.png           # MÃ©tricas de treinamento
â”‚   â”œâ”€â”€ confusion_matrix.png  # Matriz de confusÃ£o
â”‚   â”œâ”€â”€ F1_curve.png          # Curva F1-Score
â”‚   â””â”€â”€ P_curve.png           # Curva Precision
â”œâ”€â”€ ğŸ“„ pyproject.toml          # ConfiguraÃ§Ãµes do projeto
â””â”€â”€ ğŸ“„ README.md               # Este arquivo
```

## ğŸ’» Exemplos de CÃ³digo

### DetecÃ§Ã£o BÃ¡sica

```python
from ultralytics import YOLO
import cv2

# Carrega o modelo treinado
model = YOLO("output/primeiro_treinamento/file_tuning.pt")

# Realiza detecÃ§Ã£o em uma imagem
image = cv2.imread("test1.png")
results = model(image, conf=0.483)

# Visualiza resultados
annotated = results[0].plot()
cv2.imshow("Detections", annotated)
```

### TraduÃ§Ã£o em Tempo Real

```python
from app import MangaTranslator

# Inicializa o tradutor
translator = MangaTranslator(
    model_path="output/primeiro_treinamento/file_tuning.pt",
    target_language="portuguÃªs"
)

# Inicia captura e traduÃ§Ã£o
translator.start_translation()
```

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸ¯ Trabalhos Futuros

- [ ] Suporte para mÃºltiplos idiomas simultÃ¢neos
- [ ] Interface grÃ¡fica mais intuitiva
- [ ] DetecÃ§Ã£o de onomatopeias
- [ ] AdaptaÃ§Ã£o para diferentes tipos de quadrinhos
- [ ] API REST para integraÃ§Ã£o externa
- [ ] Modelo mais leve para dispositivos mÃ³veis

## ğŸ“ Contato

Desenvolvido por [Seu Nome] - [daniel_7799@live.com]

Link do Projeto: [https://github.com/Natsuzera/MangaTranslate](https://github.com/Natsuzera/MangaTranslate)
